{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm \n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code is focused on formatting the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saumy\\AppData\\Local\\Temp\\ipykernel_35276\\3941433123.py:1: DtypeWarning: Columns (282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_work = pd.read_csv('emailsWork.csv')[[\"Body\", \"Label\"]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work         2718\n",
      "Promotion    1985\n",
      "school       1970\n",
      "Blog          995\n",
      "Name: Label, dtype: int64 (7668, 2)\n"
     ]
    }
   ],
   "source": [
    "df_work = pd.read_csv('emailsWork.csv')[[\"Body\", \"Label\"]]\n",
    "df_promotions = pd.read_csv(\"emailsPromo.csv\")[[\"Body\", \"Label\"]]\n",
    "df_blog = pd.read_csv(\"current.csv\")[[\"Body\", \"Label\"]]\n",
    "\n",
    "maindf = pd.concat([df_work, df_promotions, df_blog])\n",
    "labels = maindf[\"Label\"].unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, label in enumerate(labels):\n",
    "    label_dict[label] = index\n",
    "\n",
    "print(maindf.Label.value_counts(), maindf.shape)\n",
    "\n",
    "maindf.Label = maindf.Label.replace(label_dict)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(maindf.Body.values, maindf.Label.values, test_size=0.15, random_state=seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the train and test data to be fed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\saumy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case = True)\n",
    "\n",
    "etrain = tokenizer.batch_encode_plus(Xtrain, add_special_tokens = True, return_attention_mask = True, pad_to_max_length = True, max_length=256, return_tensors = \"pt\")\n",
    "etest = tokenizer.batch_encode_plus(\n",
    "    Xtest, add_special_tokens=True, return_attention_mask=True, pad_to_max_length=True, max_length=256, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = etrain[\"input_ids\"]\n",
    "attention_masks_train = etrain[\"attention_mask\"]\n",
    "labels_train = torch.tensor(ytrain)\n",
    "\n",
    "input_ids_test = etest[\"input_ids\"]\n",
    "attention_masks_test = etest[\"attention_mask\"]\n",
    "labels_test = torch.tensor(ytest)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\saumy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_dict), output_attentions=False, output_hidden_states=False)\n",
    "model = model.to(device)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=3)\n",
    "dataloader_test = DataLoader(dataset_test, sampler=RandomSampler(dataset_test), batch_size=3)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train)*epochs)\n",
    "\n",
    "#scoring methods\n",
    "def f1_score_(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average=\"weighted\")\n",
    "def accuracy(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Not Run the code below, It will run for more than an hour, this is for training the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [],[]\n",
    "\n",
    "    for batch  in dataloader:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[0],\n",
    "            \"attention_mask\": batch[1],\n",
    "            \"labels\": batch[2],\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs[\"labels\"].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total/len(dataloader)\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "    \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "# for epoch in tqdm(range(1, epochs + 1)):\n",
    "#     model.train()\n",
    "\n",
    "#     loss_train_total = 0\n",
    "\n",
    "#     progress = tqdm(dataloader_train, desc=\"Epoch {:1d}\".format(epoch), leave=False, disable=False)\n",
    "#     for batch in progress:\n",
    "#         model.zero_grad()\n",
    "\n",
    "#         batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "#         inputs = {\n",
    "#             \"input_ids\": batch[0],\n",
    "#             \"attention_mask\": batch[1],\n",
    "#             \"labels\": batch[2],\n",
    "#         }\n",
    "\n",
    "#         outputs = model(**inputs)\n",
    "\n",
    "#         loss = outputs[0]\n",
    "#         loss_train_total += loss.item()\n",
    "#         loss.backward()\n",
    "\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "\n",
    "#         progress.set_postfix({\"training_loss\": \"{:.3f}\".format(loss.item()/len(batch))})\n",
    "    \n",
    "#     torch.save(model.state_dict(),\n",
    "#                f'./models/finetuned_BERT_epoch_{epoch}.model')\n",
    "\n",
    "#     tqdm.write(f'\\nEpoch {epoch}')\n",
    "\n",
    "#     loss_training_avg = loss_train_total/len(dataloader_train)\n",
    "#     tqdm.write(f'Training Loss: {loss_training_avg}')\n",
    "\n",
    "#     val_loss, predictions, true_vals = evaluate(dataloader_test)\n",
    "#     val_f1 = f1_score_(predictions, true_vals)\n",
    "#     tqdm.write(f'Validation loss: {val_loss}')\n",
    "#     tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Work\n",
      "Accuracy: 428/430\n",
      "\n",
      "Class: Promotion\n",
      "Accuracy: 267/273\n",
      "\n",
      "Class: Blog\n",
      "Accuracy: 162/163\n",
      "\n",
      "Class: school\n",
      "Accuracy: 285/285\n",
      "\n",
      "F1 Score: 0.9921705781220846\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = len(label_dict), output_attentions=False, output_hidden_states=False)\n",
    "\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('./models/finetuned_BERT_epoch_5.model', map_location=torch.device('cuda:0')))\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_test)\n",
    "accuracy(predictions, true_vals)\n",
    "val_f1 = f1_score_(predictions, true_vals)\n",
    "print(f'F1 Score: {val_f1}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
